<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Holodepth: Programmable Depth-Varying Projection</title>
    <link rel="icon" href="https://imaging.cs.cmu.edu/wp-content/uploads/2020/10/favicon.png" sizes="32x32" />
    <link rel="icon" href="https://imaging.cs.cmu.edu/wp-content/uploads/2020/10/favicon.png" sizes="192x192" />
    <link rel="apple-touch-icon" href="https://imaging.cs.cmu.edu/wp-content/uploads/2020/10/favicon.png" />

    <!-- <link href="web/bootstrap.css" rel="stylesheet"/> -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-YvpcrYf0tY3lHB60NNkmXc5s9fDVZLESaAA55NDzOxhy9GkcIdslK1eN7N6jIeHz" crossorigin="anonymous"></script>
    <link href="web/main.css" rel="stylesheet"/>

    <style>
        #navbar_content > li a:hover:not(#home) {
            background-color: #111;
        }

        #home {
            background-color: #2c5fb0;
        }
    </style>
  </head>
  <body>
    <div class="text-center bg-body-tertiary">
        <div class="container py-5">
            <h1>Holodepth: Programmable Depth&#x2011;Varying Projection via Computer&#x2011;Generated Holography | ECCV&nbsp;2024</h1>
            <p class="fs-5"><a href="https://dorianchan.com/" target="_blank">Dorian Chan</a>, <a href="https://www.cs.cmu.edu/~motoole2"  target="_blank">Matthew O'Toole</a>, <a href="https://sizhuoma.netlify.app/" target="_blank">Sizhuo Ma</a>, and <a href="https://jianwang-cmu.github.io/" target="_blank">Jian Wang</a>
            </p>   
            <p><a class="btn btn-dark btn-lg" href="mainpaper.pdf" role="button">Paper</a> <a class="btn btn-dark btn-lg" href="supplement.pdf" role="button">Supplement</a> <a class="btn btn-dark btn-lg" href="https://github.com/dorianchan/holodepth" role="button">Code</a></p>
        </div>
    </div>
    <div class="container">
        <div class="teaser py-4">
            <figure class="">
                <img src="assets/teaser.png" />
                <!-- <figcaption>We leverage a holographic projector for forming depth-varying patterns. In other words, we can program unique content at multiple depths per pixel simultaneously. This capability could be useful for future interfaces, depth sensing, and more.</figcaption> -->
            </figure>
        </div>
        <p class="fs-3 py-5" style="text-align: center;font-weight: bold;">TL;DR, we built a projector that can program unique content at multiple depths per pixel simultaneously using a variant of computer-generated holography. This capability could be useful for future interfaces, depth sensing systems, and more.</p>

        <!-- <h2>Abstract</h2>
            <p>Typical projectors are designed to programmably display 2D content at a single depth. In this work, we explore how to engineer a depth-varying projector system that is capable of forming desired patterns at multiple depths. To this end, we leverage a holographic approach, but a naive implementation of such a system is limited in its depth programmability. Inspired by recent work in near-eye displays, we add a lens array to a holographic projector to maximize the depth variation of the projected content, for which we propose an optimization-driven calibration method. We demonstrate a number of applications using this system, including novel 3D interfaces for future wearables, privacy-preserving projection, depth sensing, and light curtains.</p> -->
    
        <h2>Overview</h2>
        <p>Imagine a projector that is capable of projecting <i>depth-dependent</i> content. Different images could be projected onto different objects at different depths, enabling new modalities of <a href="https://en.wikipedia.org/wiki/Projection_mapping" target="_blank">projection mapping</a> and depth sensing. The goal of our paper is to create such a projector.</p>
        <p>However, engineering such a system is a challenge using traditional projector configurations. Many past approaches, like coded aperture/light field projectors, are limited in their programmability under such a setting. Other approaches, such as multifocal systems, require high bandwidth and speed requirements, limiting their practicality. To address these challenges, we turn to <i>computer-generated holography</i>, and leverage the wave propagation of laser light to engineer a projector system. Under the right configuration, such a holographic system signficantly improves the visual quality of depth-dependent content compared to past projectors.</p>

        <div class="center"><img src="assets/compare.png"/></div>

        <br><br>
        <p>To maximize the depth variation of projected patterns, we find that the <i>&eacute;tendue</i> of the holographic system needs to be increased. We do so by introducing a lens array into the optical path, and appropriately calibrating its effects on the propagation of light within the system.</p>

        <div class="center">
            <img style="width: 40%" src="assets/etendue_a.png"/><img style="width: 40%" src="assets/etendue_b.png"/>
        </div>
        
        <br><br>
        <p>Using our hardware prototype, we demonstrate a number of potential applications of such a depth-varying projector. For instance, such a system could be used to engineer next-generation screenless AR interfaces, where users interact with a pattern projected onto their palm. Depending on where their hand is placed, a different button could potentially appear.</p>

        <div class="center">
            <img style="width: 40%" src="assets/button.png"/>
        </div>

        <br><br>
        <p>Such a projector could also be useful for depth sensing. By showing a depth-dependent projection and identifying which patterns are present on different objects, depth can be directly extracted. We can potentially even further refine the projected patterns to improve the depth reconstruction quality.</p>

        <div class="center">
            <img style="width: 70%" src="assets/depth.png"/>
        </div>


        <br><br>
        <p>This depth cue can also be used to build a light curtain system, by simply computing a difference image between the desired visible pattern and the actual visible pattern. This allows for multiple light curtains to be formed simultaneously without loss of resolution, and it does not require stereo calibration and synchronization unlike past approaches.</p>
        <div class="center">
            <img style="width: 70%" src="assets/lc.png"/>
        </div>

        <h2>Acknowledgements</h2>
        <p>We thank Benjamin Attal, Shree Nayar, and Gurunandan Krishnan for the helpful discussions, and Nancy Pollard, Srinivasa Narasimhan and Arkadeep Narayan Chaudhury for their feedback on the paper.  We also acknowledge the support of a NSF CAREER award (IIS 2238485) and a gift from Snap.</p>
    </div>
  </body>
</html>